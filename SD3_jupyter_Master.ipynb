{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mancher07/Stable-Diffusion-3/blob/main/SD3_jupyter_Master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b master https://github.com/camenduru/ComfyUI /content/MasterUI\n",
        "%cd /content/MasterUI\n",
        "\n",
        "!pip install -q torchsde einops diffusers accelerate xformers==0.0.26.post1\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/adamo1139/stable-diffusion-3-medium-ungated/resolve/main/sd3_medium_incl_clips_t5xxlfp8.safetensors -d /content/MasterUI/model -o sd3_medium_incl_clips_t5xxlfp8.safetensors\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import node_helpers\n",
        "from comfy.sd import load_checkpoint_guess_config\n",
        "import nodes\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "with torch.inference_mode():\n",
        "    model_patcher, clip, vae, clipvision = load_checkpoint_guess_config(\"/content/MasterUI/model/sd3_medium_incl_clips_t5xxlfp8.safetensors\", output_vae=True, output_clip=True, embedding_directory=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB-w5x6F9glJ"
      },
      "outputs": [],
      "source": [
        "# Función para ajustar los valores de conditioning\n",
        "def zero_out(conditioning):\n",
        "    c = []\n",
        "    for t in conditioning:\n",
        "        d = t[1].copy()\n",
        "        if \"pooled_output\" in d:\n",
        "            d[\"pooled_output\"] = torch.zeros_like(d[\"pooled_output\"])\n",
        "        n = [torch.zeros_like(t[0]), d]\n",
        "        c.append(n)\n",
        "    return (c, )\n",
        "\n",
        "# Configuración del input\n",
        "input_config = {\n",
        "    \"cfg\": 3.5,\n",
        "    \"image\": \"https://replicate.delivery/pbxt/LFL6UhoUIvCXhOzy9ndSKI7F7CoR1wzoJrrISDtOUuhcIMjK/IMG_20240710_194648.png\",\n",
        "    \"steps\": 28,\n",
        "    \"prompt\": \"A brutal slam/death metal album cover, reflecting a chaotic hell with giant titan octopus with goat skulls, macabre detail, PlayStation 5 graphics, very clear sharpness, shading on all objects, render 4D\",\n",
        "    \"aspect_ratio\": \"1:1\",\n",
        "    \"output_format\": \"png\",\n",
        "    \"output_quality\": 100,\n",
        "    \"negative_prompt\": \"verybadimagenegative_v1.3, ng_deepnegative_v1_75t, (ugly face:0.8),cross-eyed,sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, bad anatomy, DeepNegative, facing away, tilted head, {Multiple people}, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worstquality, low quality, normal quality, jpegartifacts, signature, watermark, username, blurry, bad feet, cropped, poorly drawn hands, poorly drawn face, mutation, deformed, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, extra fingers, fewer digits, extra limbs, extra arms,extra legs, malformed limbs, fused fingers, too many fingers, long neck, cross-eyed,mutated hands, polar lowres, bad body, bad proportions, gross proportions, text, error, missing fingers, missing arms, missing legs, extra digit, extra arms, extra leg, extra foot, ((repeating hair))\",\n",
        "    \"prompt_strength\": 0.5\n",
        "}\n",
        "\n",
        "with torch.inference_mode():\n",
        "    latent = {\"samples\": torch.ones([1, 16, 1024 // 8, 1024 // 8]) * 0.0609}\n",
        "\n",
        "    prompt = input_config[\"prompt\"]\n",
        "    cond, pooled = clip.encode_from_tokens(clip.tokenize(prompt), return_pooled=True)\n",
        "    cond = [[cond, {\"pooled_output\": pooled}]]\n",
        "\n",
        "    negative_prompt = input_config[\"negative_prompt\"]\n",
        "    n_cond, n_pooled = clip.encode_from_tokens(clip.tokenize(negative_prompt), return_pooled=True)\n",
        "    n_cond = [[n_cond, {\"pooled_output\": n_pooled}]]\n",
        "\n",
        "    n_cond1 = node_helpers.conditioning_set_values(n_cond, {\"start_percent\": 0, \"end_percent\": 0.1})\n",
        "    n_cond2 = zero_out(n_cond)\n",
        "    n_cond2 = node_helpers.conditioning_set_values(n_cond2[0], {\"start_percent\": 0.1, \"end_percent\": 1.0})\n",
        "    n_cond = n_cond1 + n_cond2\n",
        "\n",
        "    seed = 1\n",
        "    if seed == 0:\n",
        "        seed = random.randint(0, 18446744073709551615)\n",
        "    print(seed)\n",
        "\n",
        "    sample = nodes.common_ksampler(model=model_patcher,\n",
        "                            seed=seed,\n",
        "                            steps=input_config[\"steps\"],\n",
        "                            cfg=input_config[\"cfg\"],\n",
        "                            sampler_name=\"dpmpp_2m\",\n",
        "                            scheduler=\"sgm_uniform\",\n",
        "                            positive=cond,\n",
        "                            negative=n_cond,\n",
        "                            latent=latent,\n",
        "                            denoise=1)\n",
        "\n",
        "    sample = sample[0][\"samples\"].to(torch.float16)\n",
        "    vae.first_stage_model.cuda()\n",
        "    decoded = vae.decode_tiled(sample).detach()\n",
        "\n",
        "image_array = np.array(decoded * 255, dtype=np.uint8)[0]\n",
        "Image.fromarray(image_array).save(\"output_image.png\", format=input_config[\"output_format\"], quality=input_config[\"output_quality\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}